import streamlit as st
import requests
import base64

# ğŸ”§ Configurazione base
st.set_page_config(page_title="Screening CV con LLM", layout="centered")

st.title("ğŸ“„ Screening CV intelligente")
st.markdown("Carica il tuo CV e confrontalo con un ruolo aziendale per ricevere un feedback personalizzato.")

# ğŸ“¤ Upload del CV
uploaded_file = st.file_uploader("Carica il tuo CV (PDF o TXT)", type=["pdf", "txt"])

# ğŸ¯ Selezione ruolo aziendale
roles = ["Machine Learning Engineer","Data Scientist", "Backend Developer", "IT Support", "HR Specialist", "Project Manager"]
selected_role = st.selectbox("Ruolo da confrontare", roles)

# ğŸ§  Invio al backend
if st.button("Analizza CV") and uploaded_file and selected_role:
    with st.spinner("Analisi in corso..."):
        # ğŸ” Conversione file in base64
        file_bytes = uploaded_file.read()
        encoded_file = base64.b64encode(file_bytes).decode("utf-8")

        # ğŸ“¡ Chiamata API
        response = requests.post(
            "http://localhost:8000/screening",
            json={
                "filename": uploaded_file.name,
                "filedata": encoded_file,
                "role": selected_role
            }
        )

        if response.status_code == 200:
            result = response.json()
            st.success("âœ… Analisi completata!")
            st.subheader("ğŸ“Š Feedback")
            st.markdown(result["feedback"])
        else:
            st.error("âŒ Errore durante l'analisi. Controlla il backend.")

# ğŸ§¾ Footer
st.markdown("---")
st.caption("Powered by LangChain + FastAPI + LLM open-source")